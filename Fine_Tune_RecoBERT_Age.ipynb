{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/prateekjoshi565/Fine-Tuning-BERT/blob/master/Fine_Tuning_BERT_for_Spam_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OFOTiqrtNvyy"
   },
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x4giRzM7NtHJ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import classification_report\n",
    "import transformers\n",
    "from sklearn.metrics import accuracy_score\n",
    "import random\n",
    "\n",
    "\n",
    "# specify GPU or CPU\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kKd-Tj3hOMsZ"
   },
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#samples = list(open('original_desen.csv', \"r\").readlines())\n",
    "samples = list(open('desen_random_2k.txt', \"r\").readlines())\n",
    "\n",
    "# Take 80% of the data as fine-tuning dataset since 80% of the data was used for pre-training\n",
    "samples = samples[0:int(0.8*len(samples))]\n",
    "\n",
    "\n",
    "userid, qq_item_seq, kandian_item_seq, userprofile  = [], [], [], []\n",
    "\n",
    "for i in range(len(samples)):\n",
    "    \n",
    "    userid.append(int(samples[i].split(\",,\")[0]))\n",
    "        \n",
    "    qq_item_seq_temp = [int(digit) for digit in samples[i].split(\",,\")[1].split(\",\")]\n",
    "    qq_item_seq.append(qq_item_seq_temp)\n",
    "    \n",
    "    kandian_item_seq_temp = [int(digit) for digit in samples[i].split(\",,\")[2].split(\",\")]\n",
    "    kandian_item_seq.append(kandian_item_seq_temp)\n",
    "    \n",
    "    userprofile_temp = [int(digit) for digit in samples[i].split(\",,\")[3].split(\",\")]\n",
    "    userprofile.append(userprofile_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_target = np.array(userprofile)[:,0]\n",
    "#gender_target = list(gender_target)\n",
    "\n",
    "age_target = np.array(userprofile)[:,1]\n",
    "#age_target = list(age_target)\n",
    "\n",
    "#qq_item_seq = np.array(qq_item_seq)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600, 1600, 1600)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(qq_item_seq), len(age_target), len(gender_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index to exclude: 909\n",
      "index to exclude: 1163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/numpy/lib/function_base.py:5030: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = asarray(arr)\n"
     ]
    }
   ],
   "source": [
    "# Find indices that have missing info (-1) in age target and gender target, \n",
    "# and exclude QQ sequences, age target and gender target of such indices \n",
    "indices_to_remove =[]\n",
    "for i in range(len(age_target)):\n",
    "    if age_target[i] == -1 or gender_target[i] == -1:\n",
    "        print(\"index to exclude:\", i)\n",
    "        indices_to_remove.append(i)\n",
    "\n",
    " \n",
    "gender_target = list(np.delete(gender_target, indices_to_remove))\n",
    "age_target = list(np.delete(age_target, indices_to_remove))\n",
    "qq_item_seq = list(np.delete(qq_item_seq, indices_to_remove))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1598, 1598, 1598)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(qq_item_seq), len(age_target), len(gender_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age distribution:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({3: 638, 4: 387, 2: 365, 5: 162, 6: 36, 7: 5, 1: 4, 9: 1})\n",
      "\n",
      "\n",
      "Gender distribution:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 1170, 2: 428})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot histogram of Age and Gender dataset \n",
    "print(\"Age distribution:\")\n",
    "y=np.array(age_target)\n",
    "plt.hist(y)\n",
    "plt.show()\n",
    "count =Counter(list(y))\n",
    "print(count)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Gender distribution:\")\n",
    "y=np.array(gender_target)\n",
    "plt.hist(y)\n",
    "plt.show()\n",
    "count =Counter(list(y))\n",
    "print(count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only 1 element: 0.42125\n",
      "Only 2 elements: 0.23875\n",
      "Only 3 elements: 0.139375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({2: 382, 1: 674, 4: 188, 3: 223, 5: 133})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "# Plot Kandian items distribution {x-axis = number of elements in each kandian sequence, y-axis = counts }\n",
    "train, train_target, test = {}, {}, {}\n",
    "length_list = []\n",
    "user_index = 0\n",
    "flat_seq = []\n",
    "for user in range(len(userid)):\n",
    "    kandian_seq = kandian_item_seq[user]      \n",
    "    length_list.append(len(kandian_seq))\n",
    "   \n",
    "y=np.array(length_list)\n",
    "plt.hist(y)\n",
    "plt.show()\n",
    "\n",
    "# Top 3 highest counts by percentage \n",
    "count = Counter(length_list)\n",
    "# Only 1 eleemnt in kandian \n",
    "print(\"Only 1 element:\",count.most_common()[0][1]/(count.most_common()[0][1]+count.most_common()[1][1]+count.most_common()[2][1]+\n",
    " count.most_common()[3][1]+ count.most_common()[4][1]))\n",
    "\n",
    "\n",
    "print(\"Only 2 elements:\",count.most_common()[1][1]/(count.most_common()[0][1]+count.most_common()[1][1]+count.most_common()[2][1]+\n",
    " count.most_common()[3][1]+ count.most_common()[4][1]))\n",
    "\n",
    "\n",
    "print(\"Only 3 elements:\",count.most_common()[2][1]/(count.most_common()[0][1]+count.most_common()[1][1]+count.most_common()[2][1]+\n",
    " count.most_common()[3][1]+ count.most_common()[4][1]))\n",
    "\n",
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_user_sequence(qq_item_seq, maxlen, ft_special_token):\n",
    "    batch = []\n",
    "    input_ls, seg_ls, masked_pos = [],[],[]\n",
    "    \n",
    "    for i in range(len(qq_item_seq)):\n",
    "        \n",
    "        # For 100 sequence length, we take the last 98 tokens from one sequence of training set, \n",
    "        # plus 2 special tokens: 1 [CLS], and 2 [SEP] tokens.   \n",
    "        tokens_a = qq_item_seq[i]\n",
    "        tokens_a = tokens_a[-(maxlen-2):]\n",
    "        input_ids = [ft_special_token['[CLS]']] + tokens_a + [ft_special_token['[SEP]']] \n",
    "\n",
    "        # Assign 1 to all tokens as segment ids \n",
    "        segment_ids = [1] * (1 + len(tokens_a) + 1) \n",
    "\n",
    "        \n",
    "        # Zero Paddings\n",
    "        n_pad = maxlen - len(input_ids)\n",
    "        input_ids.extend([0] * n_pad)\n",
    "        segment_ids.extend([0] * n_pad)\n",
    "        \n",
    "        \n",
    "        # Append batch data, and input ids, and segment ids\n",
    "        batch.append([input_ids, segment_ids]) \n",
    "        input_ls.append(input_ids)\n",
    "        seg_ls.append(segment_ids)\n",
    "        \n",
    "        \n",
    "        # Get all token indices other than indices from special tokens\n",
    "        cand_maked_pos = [i for i, token in enumerate(input_ids) \n",
    "                          if token != ft_special_token['[CLS]'] and token != ft_special_token['[SEP]'] and token != ft_special_token['[PAD]'] ]\n",
    "        \n",
    "        # Get 2 random masked positions  \n",
    "        random.shuffle(cand_maked_pos)\n",
    "        temp_masked_pos = []\n",
    "        for pos in cand_maked_pos[:2]:\n",
    "            temp_masked_pos.append(pos)\n",
    "        masked_pos.append(temp_masked_pos)\n",
    "           \n",
    "  \n",
    "    return batch, input_ls, seg_ls , masked_pos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1598"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(qq_item_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create vocabs dictionary for qq items sequence \n",
    "vocab_to_int, int_to_vocab = {}, {}\n",
    "total_vocab = []\n",
    "for user in range(len(qq_item_seq)):\n",
    "    qq_seq = qq_item_seq[user]\n",
    "    for vocab in qq_seq:\n",
    "        total_vocab.append(vocab)\n",
    "    \n",
    "    \n",
    "for index, vocab  in enumerate(set(total_vocab)):\n",
    "    vocab_to_int[vocab] = index+1\n",
    "    int_to_vocab[index+1] = vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88284"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(int_to_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create QQ items sequence using the vocabs dictionary\n",
    "train, train_target, test = {}, {}, {}\n",
    "length_list = []\n",
    "user_index = 0\n",
    "flat_seq = []\n",
    "qq_seq_int = []\n",
    "for user in range(len(qq_item_seq)):\n",
    "    qq_seq = qq_item_seq[user]\n",
    "    \n",
    "    qq_seq_int_temp = []\n",
    "    for vocab in qq_seq:\n",
    "        qq_seq_int_temp.append(vocab_to_int[vocab])\n",
    "    \n",
    "    length_list.append(len(qq_seq_int))\n",
    "    \n",
    "    qq_seq_int.append(qq_seq_int_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 100\n",
    "\n",
    "# Define special tokens\n",
    "ft_special_token = {'[PAD]': 0, '[CLS]': max(int_to_vocab)+1, '[SEP]': max(int_to_vocab)+2 }\n",
    "\n",
    "# Create batch, input ids, and masked positions\n",
    "batch, input_ls, seg_ls, masked_pos = make_user_sequence(qq_seq_int, maxlen, ft_special_token)\n",
    "\n",
    "# Total vocab size\n",
    "vocab_size = max(int_to_vocab)+4+15578"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[88285, 25869, 5902, 4177, 3395, 17292, 20829, 3199, 7374, 4223, 11347, 24163, 17021, 19199, 82280, 24594, 6425, 62224, 83871, 25536, 26921, 39968, 17714, 5188, 571, 15844, 22959, 25993, 13914, 5998, 48122, 5233, 15629, 4315, 7144, 12119, 2, 57240, 428, 85274, 25530, 44794, 765, 26787, 883, 20852, 39225, 51791, 34576, 64399, 2761, 25531, 31643, 12142, 25565, 21825, 8447, 22750, 7312, 1416, 35167, 8417, 715, 28184, 30534, 37536, 5623, 15012, 34889, 32540, 11870, 12144, 12779, 12089, 24951, 34454, 17389, 6404, 71700, 32893, 35436, 6400, 88286, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "print(batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain length of label set\n",
    "kandian_labels = [seq[0] for seq in kandian_item_seq]\n",
    "kandian_label_vocab = len(set(kandian_labels))\n",
    "\n",
    "gender_label_vocab = len(set(gender_target))\n",
    "\n",
    "age_label_vocab = len(set(age_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({1, 2, 3, 4, 5, 6, 7, 9}, {1, 2})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(age_target), set(gender_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_dict = {}\n",
    "dict_to_label = {}\n",
    "kandian_dict_labels = []\n",
    "age_dict_labels = []\n",
    "gender_dict_labels = []\n",
    "age_dict_labels = []\n",
    "\n",
    "# Create Age target dataset from vocab dictionary\n",
    "for index, label in enumerate (set(age_target)):\n",
    "    label_to_dict[label] = index\n",
    "    dict_to_label[index] = label\n",
    "    \n",
    "for label in age_target:\n",
    "    age_dict_labels.append(label_to_dict[label]) \n",
    "    \n",
    "    \n",
    "# Create Kandian target dataset from vocab dictionary   \n",
    "#for index, label in enumerate (set(kandian_labels)):\n",
    "#    label_to_dict[label] = index\n",
    "#    dict_to_label[index] = label\n",
    "\n",
    "#for label in kandian_labels: \n",
    "#    kandian_dict_labels.append(label_to_dict[label])  \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1, 1: 2, 2: 3, 3: 4, 4: 5, 5: 6, 6: 7, 7: 9}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_to_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_to_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[88285, 25869, 5902, 4177, 3395, 17292, 20829, 3199, 7374, 4223, 11347, 24163, 17021, 19199, 82280, 24594, 6425, 62224, 83871, 25536, 26921, 39968, 17714, 5188, 571, 15844, 22959, 25993, 13914, 5998, 48122, 5233, 15629, 4315, 7144, 12119, 2, 57240, 428, 85274, 25530, 44794, 765, 26787, 883, 20852, 39225, 51791, 34576, 64399, 2761, 25531, 31643, 12142, 25565, 21825, 8447, 22750, 7312, 1416, 35167, 8417, 715, 28184, 30534, 37536, 5623, 15012, 34889, 32540, 11870, 12144, 12779, 12089, 24951, 34454, 17389, 6404, 71700, 32893, 35436, 6400, 88286, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(input_ls[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MKfWnApvOoE7"
   },
   "source": [
    "# Split train dataset into train, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mfhSPF5jOWb7"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Split dataset into training, validation, and testing dataset\n",
    "def train_test_split(train_split_size, test_split_size, input_ls, seg_ls ):\n",
    "    # Split between train and evaluation\n",
    "    split_index = np.round(int(train_split_size*len(input_ls)))\n",
    "    train_seq,  temp_seq = input_ls[0:split_index], input_ls[split_index:]\n",
    "    #train_labels, temp_labels = kandian_dict_labels[0:split_index], kandian_dict_labels[split_index:] \n",
    "    train_labels, temp_labels = age_dict_labels[0:split_index], age_dict_labels[split_index:]\n",
    "    train_segment, temp_segment = seg_ls[0:split_index], seg_ls[split_index:]\n",
    "    train_tok_pos, temp_tok_pos = masked_pos[0:split_index], masked_pos[split_index:]\n",
    "    \n",
    "    \n",
    "    # Split between evaluation and test \n",
    "    split_index = np.round(int(test_split_size*len(temp_seq)))\n",
    "    test_seq, val_seq = temp_seq[0:split_index], temp_seq[split_index:]\n",
    "    test_labels, val_labels = temp_labels[0:split_index], temp_labels[split_index:] \n",
    "    test_segment, val_segment = temp_segment[0:split_index], temp_segment[split_index:] \n",
    "    test_tok_pos, val_tok_pos = temp_tok_pos[0:split_index], temp_tok_pos[split_index:]\n",
    "    \n",
    "    return train_seq, train_labels, val_seq, val_labels, test_seq, test_labels, train_segment, val_segment, test_segment, train_tok_pos, val_tok_pos, test_tok_pos  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_seq, tr_labels, v_seq, v_labels, te_seq, te_labels, tr_segment, v_segment, te_segment, tr_tok, v_tok, te_tok= train_test_split(0.7, 0.5, input_ls, seg_ls )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[88285, 1187, 4696, 72076, 5569, 4585, 5855, 83724, 83723, 48543, 79246, 1907, 1483, 15871, 1887, 35325, 3570, 4370, 16333, 5379, 31028, 41786, 48528, 242, 86630, 27020, 3569, 268, 9787, 83587, 48538, 86622, 870, 12440, 6572, 83834, 37214, 3947, 83835, 3320, 2835, 7082, 1175, 47683, 41783, 83824, 1422, 41905, 8310, 41904, 5811, 23342, 5745, 71373, 6206, 20988, 4051, 17589, 19917, 2617, 14871, 13307, 83555, 802, 86678, 4643, 26020, 26506, 26507, 783, 9210, 12, 11662, 2496, 2394, 6241, 86751, 4573, 1046, 4167, 3453, 3091, 86734, 4515, 37212, 4735, 4662, 3487, 16648, 7906, 83842, 41889, 6108, 1399, 1663, 312, 8633, 59525, 20036, 88286]\n"
     ]
    }
   ],
   "source": [
    "print(tr_seq[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n7hsdLoCO7uB"
   },
   "source": [
    "# Import Pre-trained RecoBERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model import BERT as pre_trained\n",
    "\n",
    "# Hyperparameters for pre-trained RecoBERT\n",
    "maxlen = 100 # maximum of length\n",
    "n_layers = 1 # number of Encoder of Encoder Layer\n",
    "n_heads = 4 # number of heads in Multi-Head Attention\n",
    "emb_dim = 128 # Embedding Size\n",
    "d_ff = 128 * 4  # 4*d_model, FeedForward dimension\n",
    "d_k = d_v = 64  # dimension of K(=Q), V\n",
    "n_segments = 2 # number of segments \n",
    "\n",
    "# Load in RecoBERT weight\n",
    "pre_trained_model = pre_trained(vocab_size, maxlen, emb_dim, n_segments, d_ff, n_layers, d_k, d_v, n_heads)\n",
    "pre_trained_model.load_state_dict(torch.load(\"recmodel.bin\", map_location=torch.device('cpu')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BERT(\n",
       "  (embedding): Embedding(\n",
       "    (tok_embed): Embedding(103866, 128)\n",
       "    (pos_embed): Embedding(100, 128)\n",
       "    (seg_embed): Embedding(2, 128)\n",
       "    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (layers): ModuleList(\n",
       "    (0): EncoderLayer(\n",
       "      (enc_self_attn): MultiHeadAttention(\n",
       "        (W_Q): Linear(in_features=128, out_features=256, bias=True)\n",
       "        (W_K): Linear(in_features=128, out_features=256, bias=True)\n",
       "        (W_V): Linear(in_features=128, out_features=256, bias=True)\n",
       "      )\n",
       "      (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "      (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (activ1): Tanh()\n",
       "  (linear): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  (classifier): Linear(in_features=128, out_features=2, bias=True)\n",
       "  (decoder): Linear(in_features=128, out_features=103866, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(pre_trained_model.classifier.in_features)\n",
    "print(pre_trained_model.classifier.out_features)\n",
    "\n",
    "in_features = pre_trained_model.classifier.in_features\n",
    "\n",
    "# Freeze pre-trained model parameters\n",
    "for param in pre_trained_model.parameters():\n",
    "     param.requires_grad = False\n",
    "        \n",
    "pre_trained_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wsm8bkRZQTw9"
   },
   "source": [
    "# Convert Integer Sequences to Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QR-lXwmzQPd6"
   },
   "outputs": [],
   "source": [
    "# Create tensors for training set\n",
    "train_seq = torch.tensor(tr_seq)\n",
    "train_mask = torch.tensor(tr_segment)\n",
    "train_y = torch.tensor(tr_labels)\n",
    "train_tok_pos = torch.tensor(tr_tok)\n",
    "\n",
    "\n",
    "# Create tensors for validation set\n",
    "val_seq = torch.tensor(v_seq)\n",
    "val_mask = torch.tensor(v_segment)\n",
    "val_y = torch.tensor(v_labels)\n",
    "val_tok_pos = torch.tensor(v_tok)\n",
    "\n",
    "# Create tensors for testing set\n",
    "test_seq = torch.tensor(te_seq)\n",
    "test_mask = torch.tensor(te_segment)\n",
    "test_y = torch.tensor(te_labels)\n",
    "test_tok_pos = torch.tensor(te_tok)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1118, 1118, 1118)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_seq), len(train_mask), len(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 240, 240)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(v_seq), len(v_segment), len(v_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 240, 240)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(te_seq), len(te_segment), len(te_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ov1cOBlcRLuk"
   },
   "source": [
    "# Create DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qUy9JKFYQYLp"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "#define a batch size\n",
    "batch_size = 10\n",
    "\n",
    "# wrap tensors\n",
    "train_data = TensorDataset(train_seq, train_mask, train_y, train_tok_pos)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "train_sampler = RandomSampler(train_data)\n",
    "\n",
    "# dataLoader for training set\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# wrap tensors\n",
    "val_data = TensorDataset(val_seq, val_mask, val_y, val_tok_pos)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "\n",
    "# dataLoader for validation set\n",
    "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)\n",
    "\n",
    "# wrap tensors\n",
    "test_data = TensorDataset(test_seq, test_mask, test_y, test_tok_pos)\n",
    "\n",
    "# sampler for sampling the data during testing\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "\n",
    "# dataLoader for testing set\n",
    "test_dataloader = DataLoader(test_data, sampler = test_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s7ahGBUWRi3X"
   },
   "source": [
    "# Define Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_to_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b3iEtGyYRd0A"
   },
   "outputs": [],
   "source": [
    "class BERT_Arch(nn.Module):\n",
    "\n",
    "    def __init__(self, pre_trained_model, cls_dim):\n",
    "      \n",
    "        super(BERT_Arch, self).__init__()\n",
    "        \n",
    "        pre_trained_model.classifier = nn.Linear(in_features, cls_dim)\n",
    "        self.bert = pre_trained_model\n",
    "\n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "        # relu activation function\n",
    "        self.relu =  nn.ReLU()\n",
    "\n",
    "        # MLP Linear layer 1\n",
    "        self.mlp_lin = nn.Linear(100,50)\n",
    "        \n",
    "        # MLP Linear classifier\n",
    "        self.mlp_lin2 = nn.Linear(50,age_label_vocab)\n",
    "        \n",
    "    \n",
    "        # Transfer learning: Linear layer 1\n",
    "        self.mask_lin = nn.Linear(103866,512)\n",
    "        \n",
    "        # Transfer learning: Linear classifier \n",
    "        self.mask_lin2 = nn.Linear(512,age_label_vocab)\n",
    "        \n",
    "    \n",
    "        #softmax activation function\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    #define the forward pass\n",
    "    def forward(self, sent_id, mask, masked_pos, device, n_heads, d_k, d_v, avg_tok=False, mlp=False):\n",
    "        \n",
    "        #pass the inputs to the model  \n",
    "        if mlp == False:\n",
    "            masked_out , cls_hs1, cls_hs2 = self.bert(sent_id, mask, masked_pos, device, n_heads, d_k, d_v)\n",
    "        \n",
    "            x = self.mask_lin(masked_out)\n",
    "            \n",
    "            x = self.relu(x)\n",
    "\n",
    "            x = self.dropout(x)\n",
    "\n",
    "            # output layer\n",
    "            x = self.mask_lin2(x)\n",
    "\n",
    "            # apply softmax activation\n",
    "            x = self.softmax(x)\n",
    "\n",
    "                \n",
    "        else:\n",
    "            sent_id = torch.tensor(sent_id, dtype=torch.float)\n",
    "            x = self.mlp_lin(sent_id)\n",
    "        \n",
    "            x = self.relu(x)\n",
    "\n",
    "            x = self.dropout(x)\n",
    "\n",
    "            # MLP linear classifier output\n",
    "            x = self.mlp_lin2(x)\n",
    "\n",
    "            # apply softmax activation\n",
    "            x = self.softmax(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j9CDpoMQR_rK"
   },
   "source": [
    "# Find Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "izY5xH5eR7Ur",
    "outputId": "4682d190-bf40-4824-89af-91983ae6b174"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 49.9375       0.54726027   0.31308777   0.51614987   1.23302469\n",
      "   5.54861111  39.95       199.75      ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "#compute the class weights\n",
    "#class_wts = compute_class_weight(class_weight='balanced', classes= np.unique(kandian_labels), y= kandian_labels)\n",
    "class_wts = compute_class_weight(class_weight='balanced', classes= np.unique(age_target), y= age_target)\n",
    "\n",
    "print(class_wts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r1WvfY2vSGKi"
   },
   "outputs": [],
   "source": [
    "# convert class weights to tensor\n",
    "weights= torch.tensor(class_wts,dtype=torch.float)\n",
    "weights = weights.to(device)\n",
    "\n",
    "# Define loss function\n",
    "cross_entropy  = nn.NLLLoss(weight=weights) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "My4CA0qaShLq"
   },
   "source": [
    "# Fine-Tune RecoBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rskLk8R_SahS"
   },
   "outputs": [],
   "source": [
    "# function to train the model\n",
    "def train(model, mlp, avg_tok):\n",
    "  \n",
    "  model.train()\n",
    "\n",
    "  total_loss, total_accuracy = 0, 0\n",
    "  \n",
    "  # empty list to save model predictions\n",
    "  total_preds=[]\n",
    "  \n",
    "  # iterate over batches\n",
    "  for step,batch in enumerate(train_dataloader):\n",
    "    \n",
    "    # push the batch to gpu\n",
    "    batch = [r.to(device) for r in batch]\n",
    " \n",
    "    sent_id, mask, labels, tok_pos = batch\n",
    "\n",
    "    # clear previously calculated gradients \n",
    "    model.zero_grad()        \n",
    "\n",
    "    # get model predictions for the current batch\n",
    "    preds = model(sent_id, mask, tok_pos , device, n_heads, \n",
    "                  d_k, d_v, avg_tok=avg_tok, mlp=mlp)\n",
    "    \n",
    "  \n",
    "    # compute the loss between actual and predicted values\n",
    "    if mlp == False:\n",
    "        preds = torch.mean(preds, dim=1)\n",
    "    \n",
    "    \n",
    "    loss = cross_entropy(preds, labels)\n",
    "\n",
    "    # add on to the total loss\n",
    "    total_loss = total_loss + loss.item()\n",
    "\n",
    "    # backward pass to calculate the gradients\n",
    "    loss.backward()\n",
    "\n",
    "    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    # model predictions are stored on GPU. So, push it to CPU\n",
    "    preds=preds.detach().cpu().numpy()\n",
    "\n",
    "    # append the model predictions\n",
    "    total_preds.append(preds)\n",
    "\n",
    "  # compute the training loss of the epoch\n",
    "  avg_loss = total_loss / len(train_dataloader)\n",
    "  \n",
    "  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
    "  # reshape the predictions in form of (number of samples, no. of classes)\n",
    "  total_preds  = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "  #returns the loss and predictions, model\n",
    "  return avg_loss, total_preds, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yGXovFDlSxB5"
   },
   "outputs": [],
   "source": [
    "# function for evaluating the model\n",
    "def evaluate(model, mlp, avg_tok):\n",
    "  \n",
    "  # deactivate dropout layers\n",
    "  model.eval()\n",
    "\n",
    "  total_loss, total_accuracy = 0, 0\n",
    "  \n",
    "  # empty list to save the model predictions\n",
    "  total_preds = []\n",
    "\n",
    "  # iterate over batches\n",
    "  for step,batch in enumerate(val_dataloader):\n",
    "\n",
    "    # push the batch to gpu\n",
    "    batch = [t.to(device) for t in batch]\n",
    "\n",
    "    sent_id, mask, labels, tok_pos = batch\n",
    "\n",
    "    # deactivate autograd\n",
    "    with torch.no_grad():\n",
    "      \n",
    "      # model predictions\n",
    "      preds = model(sent_id, mask, tok_pos , device, n_heads, \n",
    "                    d_k, d_v, avg_tok=avg_tok, mlp=mlp)\n",
    "    \n",
    "      \n",
    "      \n",
    "      if mlp == False: \n",
    "          preds = torch.mean(preds, dim=1)\n",
    "        \n",
    "        \n",
    "      # compute the validation loss between actual and predicted values\n",
    "      loss = cross_entropy(preds,labels)\n",
    "\n",
    "      total_loss = total_loss + loss.item()\n",
    "\n",
    "      preds = preds.detach().cpu().numpy()\n",
    "\n",
    "      total_preds.append(preds)\n",
    "\n",
    "  # compute the validation loss of the epoch\n",
    "  avg_loss = total_loss / len(val_dataloader) \n",
    "\n",
    "  # reshape the predictions in form of (number of samples, no. of classes)\n",
    "  total_preds  = np.concatenate(total_preds, axis=0)\n",
    "    \n",
    "\n",
    "  return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9KZEgxRRTLXG"
   },
   "source": [
    "# Start Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def start(model, mlp, epochs):\n",
    "# set initial loss to infinite\n",
    "    best_valid_loss = float('inf')\n",
    "\n",
    "    # empty lists to store training and validation loss of each epoch\n",
    "    train_losses=[]\n",
    "    valid_losses=[]\n",
    "\n",
    "    #for each epoch\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        if epoch % 20== 0:\n",
    "            print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
    "\n",
    "        #train model\n",
    "        train_loss, _, model = train(model, mlp, avg_tok=False )\n",
    "\n",
    "        #evaluate model\n",
    "        valid_loss, _ = evaluate(model, mlp, avg_tok=False)\n",
    "\n",
    "        #save the best model\n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            torch.save(model.state_dict(), 'fine_tuned_weights.pt')\n",
    "\n",
    "        # append training and validation loss\n",
    "        train_losses.append(train_loss)\n",
    "        valid_losses.append(valid_loss)\n",
    "        \n",
    "        # Print losses every 20 epochs\n",
    "        if epoch % 20== 0:\n",
    "            print(f'\\nTraining Loss: {train_loss:.3f}')\n",
    "            print(f'Validation Loss: {valid_loss:.3f}')\n",
    "\n",
    "        \n",
    "        \n",
    "    return train_losses, valid_losses, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions for test data\n",
    "def get_accuracy(model, mlp):\n",
    "    test_preds = []\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for step,batch in enumerate(test_dataloader):\n",
    "\n",
    "            # push the batch to gpu\n",
    "            batch = [t.to(device) for t in batch]\n",
    "\n",
    "            sent_id, mask, labels, tok_pos  = batch   \n",
    "            \n",
    "            \n",
    "            preds = model(sent_id, mask, tok_pos , device, n_heads, d_k, d_v, avg_tok=False, mlp=mlp)\n",
    " \n",
    "            if mlp == False:\n",
    "                preds = torch.mean(preds, dim=1)\n",
    "            preds = preds.detach().cpu().numpy()\n",
    "            test_preds.append(preds)\n",
    "\n",
    "    test_preds_concat =np.concatenate( test_preds, axis=0 )\n",
    "   \n",
    "    preds = np.argmax(test_preds_concat, axis = 1)\n",
    " \n",
    "    print(\"predicted Ages:\\n\",preds)\n",
    "    print(\"True Ages:\\n\",test_y)\n",
    "    print(\"Accuracy score: \",int(accuracy_score(test_y,preds)*100 ),\"%\")\n",
    "    \n",
    "    print(classification_report(test_y, preds))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free up memory for training\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Age Classification: Training and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model A: MLP \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mistgpu/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_474/3723802966.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sent_id = torch.tensor(sent_id, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 / 300\n",
      "\n",
      "Training Loss: 3127.034\n",
      "Validation Loss: 957.751\n",
      "\n",
      " Epoch 21 / 300\n",
      "\n",
      "Training Loss: 1.734\n",
      "Validation Loss: 6.484\n",
      "\n",
      " Epoch 41 / 300\n",
      "\n",
      "Training Loss: 1.706\n",
      "Validation Loss: 5.553\n",
      "\n",
      " Epoch 61 / 300\n",
      "\n",
      "Training Loss: 1.698\n",
      "Validation Loss: 5.547\n",
      "\n",
      " Epoch 81 / 300\n",
      "\n",
      "Training Loss: 1.720\n",
      "Validation Loss: 5.546\n",
      "\n",
      " Epoch 101 / 300\n",
      "\n",
      "Training Loss: 1.696\n",
      "Validation Loss: 5.546\n",
      "\n",
      " Epoch 121 / 300\n",
      "\n",
      "Training Loss: 1.702\n",
      "Validation Loss: 5.486\n",
      "\n",
      " Epoch 141 / 300\n",
      "\n",
      "Training Loss: 1.694\n",
      "Validation Loss: 5.494\n",
      "\n",
      " Epoch 161 / 300\n",
      "\n",
      "Training Loss: 1.707\n",
      "Validation Loss: 5.424\n",
      "\n",
      " Epoch 181 / 300\n",
      "\n",
      "Training Loss: 1.713\n",
      "Validation Loss: 5.422\n",
      "\n",
      " Epoch 201 / 300\n",
      "\n",
      "Training Loss: 1.717\n",
      "Validation Loss: 5.419\n",
      "\n",
      " Epoch 221 / 300\n",
      "\n",
      "Training Loss: 1.710\n",
      "Validation Loss: 5.419\n",
      "\n",
      " Epoch 241 / 300\n",
      "\n",
      "Training Loss: 1.723\n",
      "Validation Loss: 5.419\n",
      "\n",
      " Epoch 261 / 300\n",
      "\n",
      "Training Loss: 1.706\n",
      "Validation Loss: 5.420\n",
      "\n",
      " Epoch 281 / 300\n",
      "\n",
      "Training Loss: 1.723\n",
      "Validation Loss: 5.421\n",
      "predicted Ages:\n",
      " [2 2 2 2 1 2 2 5 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 1 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 7 2 2 2 2 2 2 2 2 2 4 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2]\n",
      "True Ages:\n",
      " tensor([2, 2, 6, 2, 4, 2, 2, 2, 3, 1, 2, 3, 2, 3, 1, 3, 2, 3, 4, 4, 4, 2, 2, 1,\n",
      "        0, 2, 2, 3, 4, 2, 3, 3, 2, 5, 3, 1, 3, 1, 1, 1, 3, 3, 2, 4, 1, 3, 3, 3,\n",
      "        2, 3, 1, 3, 2, 2, 3, 2, 1, 1, 1, 1, 2, 1, 1, 2, 2, 4, 2, 2, 3, 2, 1, 1,\n",
      "        5, 1, 3, 2, 4, 1, 2, 1, 2, 4, 3, 3, 2, 4, 3, 3, 1, 3, 1, 2, 2, 1, 3, 2,\n",
      "        1, 3, 1, 2, 3, 1, 3, 1, 1, 2, 3, 2, 2, 3, 2, 2, 3, 3, 3, 2, 2, 1, 1, 2,\n",
      "        3, 1, 3, 2, 1, 2, 2, 1, 3, 1, 2, 5, 4, 2, 3, 3, 2, 2, 1, 5, 1, 2, 2, 3,\n",
      "        2, 3, 2, 3, 2, 1, 5, 3, 3, 4, 1, 2, 2, 3, 2, 4, 2, 2, 2, 4, 1, 2, 1, 3,\n",
      "        3, 2, 4, 3, 2, 2, 2, 2, 3, 3, 2, 4, 4, 2, 3, 2, 2, 4, 3, 3, 2, 5, 1, 1,\n",
      "        2, 2, 3, 3, 1, 6, 1, 3, 3, 2, 2, 1, 2, 2, 1, 2, 2, 3, 2, 1, 2, 2, 2, 3,\n",
      "        2, 4, 2, 3, 3, 1, 2, 2, 3, 3, 2, 1, 1, 4, 2, 1, 2, 3, 4, 3, 3, 1, 2, 2])\n",
      "Accuracy score:  36 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.00      0.00      0.00        52\n",
      "           2       0.38      0.95      0.54        92\n",
      "           3       0.00      0.00      0.00        66\n",
      "           4       0.00      0.00      0.00        21\n",
      "           5       0.00      0.00      0.00         6\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.36       240\n",
      "   macro avg       0.05      0.12      0.07       240\n",
      "weighted avg       0.14      0.36      0.21       240\n",
      "\n",
      "elapsed time: 247.5142617225647\n",
      "-------------------------------------------\n",
      "Training model B: Freeze + Fine-tune \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mistgpu/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 / 300\n",
      "\n",
      "Training Loss: 0.699\n",
      "Validation Loss: 0.693\n",
      "\n",
      " Epoch 21 / 300\n",
      "\n",
      "Training Loss: 0.927\n",
      "Validation Loss: 0.693\n",
      "\n",
      " Epoch 41 / 300\n",
      "\n",
      "Training Loss: 0.960\n",
      "Validation Loss: 0.693\n",
      "\n",
      " Epoch 61 / 300\n",
      "\n",
      "Training Loss: 1.046\n",
      "Validation Loss: 0.694\n",
      "\n",
      " Epoch 81 / 300\n",
      "\n",
      "Training Loss: 1.052\n",
      "Validation Loss: 0.693\n",
      "\n",
      " Epoch 101 / 300\n",
      "\n",
      "Training Loss: 1.032\n",
      "Validation Loss: 0.693\n",
      "\n",
      " Epoch 121 / 300\n",
      "\n",
      "Training Loss: 0.999\n",
      "Validation Loss: 0.694\n",
      "\n",
      " Epoch 141 / 300\n",
      "\n",
      "Training Loss: 1.269\n",
      "Validation Loss: 0.693\n",
      "\n",
      " Epoch 161 / 300\n",
      "\n",
      "Training Loss: 1.126\n",
      "Validation Loss: 0.693\n",
      "\n",
      " Epoch 181 / 300\n",
      "\n",
      "Training Loss: 1.168\n",
      "Validation Loss: 0.693\n",
      "\n",
      " Epoch 201 / 300\n",
      "\n",
      "Training Loss: 1.179\n",
      "Validation Loss: 0.693\n",
      "\n",
      " Epoch 221 / 300\n",
      "\n",
      "Training Loss: 1.083\n",
      "Validation Loss: 0.693\n",
      "\n",
      " Epoch 241 / 300\n",
      "\n",
      "Training Loss: 1.110\n",
      "Validation Loss: 0.693\n",
      "\n",
      " Epoch 261 / 300\n",
      "\n",
      "Training Loss: 1.086\n",
      "Validation Loss: 0.693\n",
      "\n",
      " Epoch 281 / 300\n",
      "\n",
      "Training Loss: 1.118\n",
      "Validation Loss: 0.693\n",
      "predicted Ages:\n",
      " [2 3 1 3 2 2 2 2 2 7 6 2 1 2 1 4 0 4 1 2 4 3 1 1 1 4 6 5 2 2 3 3 3 5 1 2 2\n",
      " 2 3 5 4 2 5 2 2 2 3 7 2 2 2 5 4 1 1 2 2 2 4 3 2 1 1 1 2 5 2 2 3 2 2 2 2 1\n",
      " 2 1 2 1 2 6 3 5 4 2 2 1 1 2 5 1 5 2 2 2 1 2 4 2 2 2 2 3 2 2 4 2 3 3 5 2 7\n",
      " 3 2 4 2 1 2 1 0 1 1 6 1 3 2 2 7 1 5 4 0 1 2 2 2 5 2 2 2 2 3 4 2 2 1 1 2 3\n",
      " 1 2 5 3 1 2 2 2 1 6 3 4 2 2 2 1 2 2 2 1 4 2 1 7 2 5 4 4 2 2 0 1 1 2 2 2 3\n",
      " 4 3 2 2 1 3 2 3 3 2 2 2 2 2 2 5 2 2 2 2 3 2 3 2 3 3 4 2 3 3 1 2 2 1 2 2 2\n",
      " 3 1 1 6 2 1 0 0 1 2 3 3 2 3 2 2 2 2]\n",
      "True Ages:\n",
      " tensor([2, 2, 6, 2, 4, 2, 2, 2, 3, 1, 2, 3, 2, 3, 1, 3, 2, 3, 4, 4, 4, 2, 2, 1,\n",
      "        0, 2, 2, 3, 4, 2, 3, 3, 2, 5, 3, 1, 3, 1, 1, 1, 3, 3, 2, 4, 1, 3, 3, 3,\n",
      "        2, 3, 1, 3, 2, 2, 3, 2, 1, 1, 1, 1, 2, 1, 1, 2, 2, 4, 2, 2, 3, 2, 1, 1,\n",
      "        5, 1, 3, 2, 4, 1, 2, 1, 2, 4, 3, 3, 2, 4, 3, 3, 1, 3, 1, 2, 2, 1, 3, 2,\n",
      "        1, 3, 1, 2, 3, 1, 3, 1, 1, 2, 3, 2, 2, 3, 2, 2, 3, 3, 3, 2, 2, 1, 1, 2,\n",
      "        3, 1, 3, 2, 1, 2, 2, 1, 3, 1, 2, 5, 4, 2, 3, 3, 2, 2, 1, 5, 1, 2, 2, 3,\n",
      "        2, 3, 2, 3, 2, 1, 5, 3, 3, 4, 1, 2, 2, 3, 2, 4, 2, 2, 2, 4, 1, 2, 1, 3,\n",
      "        3, 2, 4, 3, 2, 2, 2, 2, 3, 3, 2, 4, 4, 2, 3, 2, 2, 4, 3, 3, 2, 5, 1, 1,\n",
      "        2, 2, 3, 3, 1, 6, 1, 3, 3, 2, 2, 1, 2, 2, 1, 2, 2, 3, 2, 1, 2, 2, 2, 3,\n",
      "        2, 4, 2, 3, 3, 1, 2, 2, 3, 3, 2, 1, 1, 4, 2, 1, 2, 3, 4, 3, 3, 1, 2, 2])\n",
      "Accuracy score:  29 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.20      0.17      0.19        52\n",
      "           2       0.41      0.49      0.45        92\n",
      "           3       0.31      0.17      0.22        66\n",
      "           4       0.16      0.14      0.15        21\n",
      "           5       0.13      0.33      0.19         6\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.29       240\n",
      "   macro avg       0.15      0.16      0.15       240\n",
      "weighted avg       0.30      0.29      0.29       240\n",
      "\n",
      "elapsed time: 594.4469027519226\n",
      "-------------------------------------------\n",
      "Training model C: Fine-tune all \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mistgpu/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 / 300\n",
      "\n",
      "Training Loss: 0.701\n",
      "Validation Loss: 0.693\n",
      "\n",
      " Epoch 21 / 300\n",
      "\n",
      "Training Loss: 0.869\n",
      "Validation Loss: 0.693\n",
      "\n",
      " Epoch 41 / 300\n",
      "\n",
      "Training Loss: 0.901\n",
      "Validation Loss: 0.693\n",
      "\n",
      " Epoch 61 / 300\n",
      "\n",
      "Training Loss: 0.950\n",
      "Validation Loss: 0.693\n",
      "\n",
      " Epoch 81 / 300\n",
      "\n",
      "Training Loss: 0.964\n",
      "Validation Loss: 0.693\n",
      "\n",
      " Epoch 101 / 300\n",
      "\n",
      "Training Loss: 0.945\n",
      "Validation Loss: 0.693\n",
      "\n",
      " Epoch 121 / 300\n",
      "\n",
      "Training Loss: 0.977\n",
      "Validation Loss: 0.693\n",
      "\n",
      " Epoch 141 / 300\n",
      "\n",
      "Training Loss: 1.024\n",
      "Validation Loss: 0.693\n",
      "\n",
      " Epoch 161 / 300\n",
      "\n",
      "Training Loss: 0.963\n",
      "Validation Loss: 0.693\n",
      "\n",
      " Epoch 181 / 300\n",
      "\n",
      "Training Loss: 0.972\n",
      "Validation Loss: 0.693\n",
      "\n",
      " Epoch 201 / 300\n",
      "\n",
      "Training Loss: 1.090\n",
      "Validation Loss: 0.693\n",
      "\n",
      " Epoch 221 / 300\n",
      "\n",
      "Training Loss: 0.974\n",
      "Validation Loss: 0.693\n",
      "\n",
      " Epoch 241 / 300\n",
      "\n",
      "Training Loss: 1.095\n",
      "Validation Loss: 0.693\n",
      "\n",
      " Epoch 261 / 300\n",
      "\n",
      "Training Loss: 1.046\n",
      "Validation Loss: 0.693\n",
      "\n",
      " Epoch 281 / 300\n",
      "\n",
      "Training Loss: 1.082\n",
      "Validation Loss: 0.693\n",
      "predicted Ages:\n",
      " [3 2 5 5 2 3 2 7 1 1 2 4 3 0 2 2 3 3 2 3 1 1 3 3 3 3 0 3 3 1 3 2 3 0 2 1 3\n",
      " 1 3 2 2 1 3 3 1 3 3 4 2 3 2 3 1 3 1 1 3 5 3 4 4 3 3 2 1 3 5 4 3 3 2 3 3 4\n",
      " 3 1 3 3 2 3 3 3 6 3 1 3 3 4 1 3 4 4 3 1 4 2 3 4 3 1 3 3 3 2 3 3 3 4 3 4 3\n",
      " 4 3 3 3 7 4 3 6 2 3 3 3 2 1 2 3 3 3 2 3 0 1 3 3 1 2 1 1 3 4 4 1 3 3 3 4 1\n",
      " 2 3 2 3 3 3 2 3 3 6 3 3 3 1 3 1 3 3 3 3 3 7 0 3 3 2 3 2 3 3 5 3 3 3 7 3 3\n",
      " 1 3 4 3 2 1 2 1 3 1 4 3 1 3 1 2 3 4 2 4 3 7 2 1 3 3 3 3 3 2 2 1 1 3 2 3 3\n",
      " 4 3 3 3 1 2 1 3 3 3 3 4 3 3 3 3 3 3]\n",
      "True Ages:\n",
      " tensor([2, 2, 6, 2, 4, 2, 2, 2, 3, 1, 2, 3, 2, 3, 1, 3, 2, 3, 4, 4, 4, 2, 2, 1,\n",
      "        0, 2, 2, 3, 4, 2, 3, 3, 2, 5, 3, 1, 3, 1, 1, 1, 3, 3, 2, 4, 1, 3, 3, 3,\n",
      "        2, 3, 1, 3, 2, 2, 3, 2, 1, 1, 1, 1, 2, 1, 1, 2, 2, 4, 2, 2, 3, 2, 1, 1,\n",
      "        5, 1, 3, 2, 4, 1, 2, 1, 2, 4, 3, 3, 2, 4, 3, 3, 1, 3, 1, 2, 2, 1, 3, 2,\n",
      "        1, 3, 1, 2, 3, 1, 3, 1, 1, 2, 3, 2, 2, 3, 2, 2, 3, 3, 3, 2, 2, 1, 1, 2,\n",
      "        3, 1, 3, 2, 1, 2, 2, 1, 3, 1, 2, 5, 4, 2, 3, 3, 2, 2, 1, 5, 1, 2, 2, 3,\n",
      "        2, 3, 2, 3, 2, 1, 5, 3, 3, 4, 1, 2, 2, 3, 2, 4, 2, 2, 2, 4, 1, 2, 1, 3,\n",
      "        3, 2, 4, 3, 2, 2, 2, 2, 3, 3, 2, 4, 4, 2, 3, 2, 2, 4, 3, 3, 2, 5, 1, 1,\n",
      "        2, 2, 3, 3, 1, 6, 1, 3, 3, 2, 2, 1, 2, 2, 1, 2, 2, 3, 2, 1, 2, 2, 2, 3,\n",
      "        2, 4, 2, 3, 3, 1, 2, 2, 3, 3, 2, 1, 1, 4, 2, 1, 2, 3, 4, 3, 3, 1, 2, 2])\n",
      "Accuracy score:  27 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.26      0.19      0.22        52\n",
      "           2       0.43      0.17      0.25        92\n",
      "           3       0.32      0.59      0.41        66\n",
      "           4       0.00      0.00      0.00        21\n",
      "           5       0.00      0.00      0.00         6\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.27       240\n",
      "   macro avg       0.13      0.12      0.11       240\n",
      "weighted avg       0.31      0.27      0.26       240\n",
      "\n",
      "elapsed time: 585.6497347354889\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# optimizer from hugging face transformers\n",
    "import time\n",
    "from transformers import AdamW\n",
    "\n",
    "# number of training epochs\n",
    "epochs = 300\n",
    "\n",
    "########################### Model A ############################\n",
    "print(\"Training model A: MLP \")\n",
    "start_time = time.time()\n",
    "modelA = BERT_Arch(pre_trained_model,300) # Initialize the fine-tuning model\n",
    "modelA = modelA.to(device)\n",
    "# define the optimizer\n",
    "optimizer = AdamW(modelA.parameters(), lr = 1e-3)\n",
    "train_losses, valid_losses, modelA = start(modelA, True, epochs)# True here means we want to turn off \n",
    "                                                        # transfer learning, and use the simple MLP model\n",
    "elapsed_time = (time.time() - start_time)\n",
    "get_accuracy(modelA, True)\n",
    "print(\"elapsed time:\" ,elapsed_time)\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "########################### Model B ############################\n",
    "print(\"Training model B: Freeze + Fine-tune \")\n",
    "start_time = time.time()\n",
    "# pass the pre-trained RecoBERT to our define architecture\n",
    "modelB = BERT_Arch(pre_trained_model,300)\n",
    "modelB = modelB.to(device)\n",
    "# define the optimizer\n",
    "optimizer = AdamW(modelB.parameters(), lr = 1e-3)\n",
    "train_losses2, valid_losses2, modelB = start(modelB,False, epochs) \n",
    "elapsed_time = (time.time() - start_time)\n",
    "get_accuracy(modelB, False)\n",
    "print(\"elapsed time:\" ,elapsed_time)\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "\n",
    "############################# Model C ############################\n",
    "print(\"Training model C: Fine-tune all \")\n",
    "start_time = time.time()\n",
    "# Unfreeze pre-trained weights\n",
    "for param in pre_trained_model.parameters():\n",
    "     param.requires_grad = True\n",
    "modelC = BERT_Arch(pre_trained_model,300)\n",
    "modelC = modelC.to(device)\n",
    "# define the optimizer\n",
    "optimizer = AdamW(modelC.parameters(), lr = 1e-3)\n",
    "train_losses3, valid_losses3, modelC = start(modelC,False, epochs)\n",
    "elapsed_time = (time.time() - start_time)\n",
    "get_accuracy(modelC, False)\n",
    "print(\"elapsed time:\" ,elapsed_time)\n",
    "print(\"-------------------------------------------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_plot = range(1, epochs+1)\n",
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(10, 7))\n",
    "axes.plot(epochs_plot, valid_losses, 'g', label='MLP')\n",
    "axes.plot(epochs_plot, valid_losses2, 'b', label='Freeze + Fine-tune ')\n",
    "axes.plot(epochs_plot, valid_losses3, 'm', label='Fine-tune all')\n",
    "axes.set(ylabel='Loss')\n",
    "axes.set(xlabel='Epochs')\n",
    "axes.legend(loc='upper right')\n",
    "axes.set_title('Fine-Tuning Validation Loss')\n",
    "plt.axis([1, 300, 0, 8])\n",
    "plt.savefig('Agenewloss1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOt9x7x5Cm/ENCEI4+c+LvL",
   "include_colab_link": true,
   "name": "Fine-Tuning BERT for Spam Classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0e580433bec2453da54c0ce9ee027401": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_73fc7587f1bb49df8a0fc87ecfac7f3c",
       "IPY_MODEL_4da1c15300b2468ab1a7e2df800ed39b"
      ],
      "layout": "IPY_MODEL_bdfd7634b8bf42aa8794ada8d9e47173"
     }
    },
    "3bb6b624b4ce4be788c38cb8d1936177": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "47862cd626cf46619a5cc505fde02276": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "49dd79a9a65044ba8345deb250ce4b24": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "4d56a47453914de3be15d7a515e5b210": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "4da1c15300b2468ab1a7e2df800ed39b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_88214abee8b9462f86369072d858ae9f",
      "placeholder": "​",
      "style": "IPY_MODEL_ed9f97f9d12a49aa939b7595ad3cb27c",
      "value": " 440M/440M [00:11&lt;00:00, 37.5MB/s]"
     }
    },
    "58cd585c531444a5b8613c2d85bab022": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "59bae99ad63d4a3a8b8d622d95f7ad07": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_47862cd626cf46619a5cc505fde02276",
      "max": 433,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_49dd79a9a65044ba8345deb250ce4b24",
      "value": 433
     }
    },
    "645d520e8a1c4f1fa202c6c68c5ce6af": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "6831c2b733d74b31a41cb6eb971a25d7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "689e66a8dff249449b5f0f5bbfffa037": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6d2355752eb74f348596a380d2347b73",
      "placeholder": "​",
      "style": "IPY_MODEL_cb5f7a2a5bcb47649703cc633f2fb685",
      "value": " 433/433 [00:00&lt;00:00, 1.98kB/s]"
     }
    },
    "6d2355752eb74f348596a380d2347b73": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "73fc7587f1bb49df8a0fc87ecfac7f3c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3bb6b624b4ce4be788c38cb8d1936177",
      "max": 440473133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_645d520e8a1c4f1fa202c6c68c5ce6af",
      "value": 440473133
     }
    },
    "88214abee8b9462f86369072d858ae9f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8cf06dad410440f78c50e3527e858905": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6831c2b733d74b31a41cb6eb971a25d7",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4d56a47453914de3be15d7a515e5b210",
      "value": 231508
     }
    },
    "94264f36ceb64d3881fed952bf579072": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "983fea7c2dc74dfaba7aa60147af85d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_59bae99ad63d4a3a8b8d622d95f7ad07",
       "IPY_MODEL_689e66a8dff249449b5f0f5bbfffa037"
      ],
      "layout": "IPY_MODEL_ccf5f7e5cc10493ca9c44b14fdec31dc"
     }
    },
    "b4bef5a685954e238b52c43eefe4c9e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8cf06dad410440f78c50e3527e858905",
       "IPY_MODEL_edf0e4c1ae214a66abb717b20e3bffad"
      ],
      "layout": "IPY_MODEL_94264f36ceb64d3881fed952bf579072"
     }
    },
    "b6423c858927455e8cbc5a953273466a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bdfd7634b8bf42aa8794ada8d9e47173": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cb5f7a2a5bcb47649703cc633f2fb685": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ccf5f7e5cc10493ca9c44b14fdec31dc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ed9f97f9d12a49aa939b7595ad3cb27c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "edf0e4c1ae214a66abb717b20e3bffad": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b6423c858927455e8cbc5a953273466a",
      "placeholder": "​",
      "style": "IPY_MODEL_58cd585c531444a5b8613c2d85bab022",
      "value": " 232k/232k [00:39&lt;00:00, 5.82kB/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

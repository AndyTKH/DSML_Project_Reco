{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/prateekjoshi565/Fine-Tuning-BERT/blob/master/Fine_Tuning_BERT_for_Spam_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OFOTiqrtNvyy"
   },
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x4giRzM7NtHJ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import classification_report\n",
    "import transformers\n",
    "from sklearn.metrics import accuracy_score\n",
    "import random\n",
    "\n",
    "\n",
    "# specify GPU or CPU\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kKd-Tj3hOMsZ"
   },
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#samples = list(open('original_desen.csv', \"r\").readlines())\n",
    "samples = list(open('desen_random_2k.txt', \"r\").readlines())\n",
    "\n",
    "# Take 80% of the data as fine-tuning dataset since 80% of the data was used for pre-training\n",
    "samples = samples[0:int(0.8*len(samples))]\n",
    "\n",
    "userid, qq_item_seq, kandian_item_seq, userprofile  = [], [], [], []\n",
    "\n",
    "for i in range(len(samples)):\n",
    "    \n",
    "    userid.append(int(samples[i].split(\",,\")[0]))\n",
    "        \n",
    "    qq_item_seq_temp = [int(digit) for digit in samples[i].split(\",,\")[1].split(\",\")]\n",
    "    qq_item_seq.append(qq_item_seq_temp)\n",
    "    \n",
    "    kandian_item_seq_temp = [int(digit) for digit in samples[i].split(\",,\")[2].split(\",\")]\n",
    "    kandian_item_seq.append(kandian_item_seq_temp)\n",
    "    \n",
    "    userprofile_temp = [int(digit) for digit in samples[i].split(\",,\")[3].split(\",\")]\n",
    "    userprofile.append(userprofile_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_target = np.array(userprofile)[:,0]\n",
    "#gender_target = list(gender_target)\n",
    "\n",
    "age_target = np.array(userprofile)[:,1]\n",
    "#age_target = list(age_target)\n",
    "\n",
    "#qq_item_seq = np.array(qq_item_seq)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600, 1600, 1600)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(qq_item_seq), len(age_target), len(gender_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index to exclude: 909\n",
      "index to exclude: 1163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/numpy/lib/function_base.py:5030: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = asarray(arr)\n"
     ]
    }
   ],
   "source": [
    "# Find indices that have missing info (-1) in age target and gender target, \n",
    "# and exclude QQ sequences, age target and gender target of such indices \n",
    "indices_to_remove =[]\n",
    "for i in range(len(age_target)):\n",
    "    if age_target[i] == -1 or gender_target[i] == -1:\n",
    "        print(\"index to exclude:\", i)\n",
    "        indices_to_remove.append(i)\n",
    "\n",
    " \n",
    "gender_target = list(np.delete(gender_target, indices_to_remove))\n",
    "age_target = list(np.delete(age_target, indices_to_remove))\n",
    "qq_item_seq = list(np.delete(qq_item_seq, indices_to_remove))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1598, 1598, 1598)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(qq_item_seq), len(age_target), len(gender_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age distribution:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({3: 638, 4: 387, 2: 365, 5: 162, 6: 36, 7: 5, 1: 4, 9: 1})\n",
      "\n",
      "\n",
      "Gender distribution:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 1170, 2: 428})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot histogram of Age and Gender dataset \n",
    "print(\"Age distribution:\")\n",
    "y=np.array(age_target)\n",
    "plt.hist(y)\n",
    "plt.show()\n",
    "count =Counter(list(y))\n",
    "print(count)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Gender distribution:\")\n",
    "y=np.array(gender_target)\n",
    "plt.hist(y)\n",
    "plt.show()\n",
    "count =Counter(list(y))\n",
    "print(count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only 1 element: 0.42125\n",
      "Only 2 elements: 0.23875\n",
      "Only 3 elements: 0.139375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({2: 382, 1: 674, 4: 188, 3: 223, 5: 133})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "# Plot Kandian items distribution {x-axis = number of elements in each kandian sequence, y-axis = counts }\n",
    "train, train_target, test = {}, {}, {}\n",
    "length_list = []\n",
    "user_index = 0\n",
    "flat_seq = []\n",
    "for user in range(len(userid)):\n",
    "    kandian_seq = kandian_item_seq[user]      \n",
    "    length_list.append(len(kandian_seq))\n",
    "   \n",
    "y=np.array(length_list)\n",
    "plt.hist(y)\n",
    "plt.show()\n",
    "\n",
    "# Top 3 highest counts by percentage \n",
    "count = Counter(length_list)\n",
    "# Only 1 eleemnt in kandian \n",
    "print(\"Only 1 element:\",count.most_common()[0][1]/(count.most_common()[0][1]+count.most_common()[1][1]+count.most_common()[2][1]+\n",
    " count.most_common()[3][1]+ count.most_common()[4][1]))\n",
    "\n",
    "\n",
    "print(\"Only 2 elements:\",count.most_common()[1][1]/(count.most_common()[0][1]+count.most_common()[1][1]+count.most_common()[2][1]+\n",
    " count.most_common()[3][1]+ count.most_common()[4][1]))\n",
    "\n",
    "\n",
    "print(\"Only 3 elements:\",count.most_common()[2][1]/(count.most_common()[0][1]+count.most_common()[1][1]+count.most_common()[2][1]+\n",
    " count.most_common()[3][1]+ count.most_common()[4][1]))\n",
    "\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling to solve imbalance classes issue by creating 742 additional samples for class 2 (1454-542)\n",
    "import random\n",
    "\n",
    "gender_cls2_indices=[i for i, e in enumerate(gender_target) if e == 2]\n",
    "random.shuffle(gender_cls2_indices)\n",
    "extra_indices = 742 - len(gender_cls2_indices)\n",
    "gender_cls2_indices.extend(gender_cls2_indices[0:extra_indices])\n",
    "\n",
    "for i in gender_cls2_indices:\n",
    "    add_qq_item_seq = qq_item_seq[i].copy()\n",
    "    random.shuffle(add_qq_item_seq)\n",
    "    qq_item_seq.append(add_qq_item_seq)\n",
    "\n",
    "gender_target.extend([2]*742)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip QQ item sequences with gender target dataset, and create lists\n",
    "temp = list(zip(gender_target, qq_item_seq))\n",
    "random.shuffle(temp)\n",
    "gender_target, qq_item_seq = zip(*temp)\n",
    "gender_target, qq_item_seq = list(gender_target), list(qq_item_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender distribution:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({2: 1170, 1: 1170})\n"
     ]
    }
   ],
   "source": [
    "# Plot histogram of gender dataset after resampling\n",
    "print(\"Gender distribution:\")\n",
    "y=np.array(gender_target)\n",
    "plt.hist(y)\n",
    "plt.show()\n",
    "count =Counter(list(y))\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kandian_item_seq\n",
    "\n",
    "def make_user_sequence(qq_item_seq, maxlen, ft_special_token):\n",
    "    batch = []\n",
    "    input_ls, seg_ls, masked_pos = [],[],[]\n",
    "    \n",
    "    for i in range(len(qq_item_seq)):\n",
    "        \n",
    "        # For 100 sequence length, we take the last 98 tokens from one sequence of training set, \n",
    "        # plus 2 special tokens: 1 [CLS], and 2 [SEP] tokens.    \n",
    "        tokens_a = qq_item_seq[i]\n",
    "        tokens_a = tokens_a[-(maxlen-2):]\n",
    "        input_ids = [ft_special_token['[CLS]']] + tokens_a + [ft_special_token['[SEP]']] \n",
    "\n",
    "        # Assign 1 to all tokens as segment ids \n",
    "        segment_ids = [1] * (1 + len(tokens_a) + 1) \n",
    "\n",
    "        \n",
    "        # Zero Paddings\n",
    "        n_pad = maxlen - len(input_ids)\n",
    "        input_ids.extend([0] * n_pad)\n",
    "        segment_ids.extend([0] * n_pad)\n",
    "        \n",
    "        # Append batch data, and input ids, and segment ids\n",
    "        batch.append([input_ids, segment_ids]) \n",
    "        input_ls.append(input_ids)\n",
    "        seg_ls.append(segment_ids)\n",
    "        \n",
    "        \n",
    "        # Get all token indices other than indices from special tokens\n",
    "        cand_maked_pos = [i for i, token in enumerate(input_ids) \n",
    "                          if token != ft_special_token['[CLS]'] and token != ft_special_token['[SEP]'] and token != ft_special_token['[PAD]'] ]\n",
    "        \n",
    "        \n",
    "        # Get 2 random masked positions  \n",
    "        random.shuffle(cand_maked_pos)\n",
    "        temp_masked_pos = []\n",
    "        for pos in cand_maked_pos[:2]:\n",
    "            temp_masked_pos.append(pos)\n",
    "        masked_pos.append(temp_masked_pos)\n",
    "           \n",
    "  \n",
    "    return batch, input_ls, seg_ls , masked_pos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2340"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(qq_item_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create vocabs dictionary for qq items sequence\n",
    "vocab_to_int, int_to_vocab = {}, {}\n",
    "total_vocab = []\n",
    "for user in range(len(qq_item_seq)):\n",
    "    qq_seq = qq_item_seq[user]\n",
    "    for vocab in qq_seq:\n",
    "        total_vocab.append(vocab)\n",
    "    \n",
    "    \n",
    "for index, vocab  in enumerate(set(total_vocab)):\n",
    "    vocab_to_int[vocab] = index+1\n",
    "    int_to_vocab[index+1] = vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88284"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(int_to_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create QQ items sequence using the vocabs dictionary\n",
    "train, train_target, test = {}, {}, {}\n",
    "length_list = []\n",
    "user_index = 0\n",
    "flat_seq = []\n",
    "qq_seq_int = []\n",
    "for user in range(len(qq_item_seq)):\n",
    "    qq_seq = qq_item_seq[user]\n",
    "    \n",
    "    #for s in qq_seq:\n",
    "    #    flat_seq.append(s)\n",
    "    qq_seq_int_temp = []\n",
    "    for vocab in qq_seq:\n",
    "        qq_seq_int_temp.append(vocab_to_int[vocab])\n",
    "    \n",
    "    length_list.append(len(qq_seq_int))\n",
    "    \n",
    "    qq_seq_int.append(qq_seq_int_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 100\n",
    "\n",
    "# Define special tokens\n",
    "ft_special_token = {'[PAD]': 0, '[CLS]': max(int_to_vocab)+1, '[SEP]': max(int_to_vocab)+2 }\n",
    "\n",
    "# Create batch, input ids, and masked positions\n",
    "batch, input_ls, seg_ls, masked_pos = make_user_sequence(qq_seq_int, maxlen, ft_special_token)\n",
    "\n",
    "# Total vocab size\n",
    "vocab_size = max(int_to_vocab)+4+15578"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[88285, 1060, 16381, 17017, 76176, 6113, 111, 4202, 3465, 1215, 5379, 4187, 13722, 8859, 1221, 9116, 7330, 1042, 3106, 2630, 3155, 4040, 1052, 5631, 4539, 88286, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "print(batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain length of label set\n",
    "kandian_labels = [seq[0] for seq in kandian_item_seq]\n",
    "kandian_label_vocab = len(set(kandian_labels))\n",
    "\n",
    "gender_label_vocab = len(set(gender_target))\n",
    "\n",
    "age_label_vocab = len(set(age_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({1, 2, 3, 4, 5, 6, 7, 9}, {1, 2})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(age_target), set(gender_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_dict = {}\n",
    "dict_to_label = {}\n",
    "kandian_dict_labels = []\n",
    "age_dict_labels = []\n",
    "gender_dict_labels = []\n",
    "age_dict_labels = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create gender target dataset from vocab dictionary    \n",
    "for index, label in enumerate (set(gender_target)):\n",
    "    label_to_dict[label] = index\n",
    "    dict_to_label[index] = label    \n",
    "    \n",
    "for label in gender_target:\n",
    "    gender_dict_labels.append(label_to_dict[label]) \n",
    "    \n",
    "\n",
    "    \n",
    "# for Kandian target    \n",
    "#for index, label in enumerate (set(kandian_labels)):\n",
    "#    label_to_dict[label] = index\n",
    "#    dict_to_label[index] = label\n",
    "\n",
    "#for label in kandian_labels: \n",
    "#    kandian_dict_labels.append(label_to_dict[label])  \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1, 1: 2}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_to_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_to_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[88285, 1060, 16381, 17017, 76176, 6113, 111, 4202, 3465, 1215, 5379, 4187, 13722, 8859, 1221, 9116, 7330, 1042, 3106, 2630, 3155, 4040, 1052, 5631, 4539, 88286, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(input_ls[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MKfWnApvOoE7"
   },
   "source": [
    "# Split train dataset into train, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mfhSPF5jOWb7"
   },
   "outputs": [],
   "source": [
    "# Split dataset into training, validation, and testing dataset\n",
    "def train_test_split(train_split_size, test_split_size, input_ls, seg_ls ):\n",
    "    # Split between train and evaluation\n",
    "    split_index = np.round(int(train_split_size*len(input_ls)))\n",
    "    train_seq,  temp_seq = input_ls[0:split_index], input_ls[split_index:]\n",
    "    #train_labels, temp_labels = kandian_dict_labels[0:split_index], kandian_dict_labels[split_index:] \n",
    "    train_labels, temp_labels = gender_dict_labels[0:split_index], gender_dict_labels[split_index:]\n",
    "    train_segment, temp_segment = seg_ls[0:split_index], seg_ls[split_index:]\n",
    "    train_tok_pos, temp_tok_pos = masked_pos[0:split_index], masked_pos[split_index:]\n",
    "    \n",
    "    \n",
    "    # Split between evaluation and test \n",
    "    split_index = np.round(int(test_split_size*len(temp_seq)))\n",
    "    test_seq, val_seq = temp_seq[0:split_index], temp_seq[split_index:]\n",
    "    test_labels, val_labels = temp_labels[0:split_index], temp_labels[split_index:] \n",
    "    test_segment, val_segment = temp_segment[0:split_index], temp_segment[split_index:] \n",
    "    test_tok_pos, val_tok_pos = temp_tok_pos[0:split_index], temp_tok_pos[split_index:]\n",
    "    \n",
    "    return train_seq, train_labels, val_seq, val_labels, test_seq, test_labels, train_segment, val_segment, test_segment, train_tok_pos, val_tok_pos, test_tok_pos  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_seq, tr_labels, v_seq, v_labels, te_seq, te_labels, tr_segment, v_segment, te_segment, tr_tok, v_tok, te_tok= train_test_split(0.7, 0.5, input_ls, seg_ls )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[88285, 316, 69154, 57382, 59213, 24, 9470, 12057, 64071, 5387, 68186, 39162, 21713, 536, 68154, 82317, 14304, 38099, 29604, 46040, 948, 53230, 4007, 12967, 64081, 13212, 88286, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(tr_seq[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n7hsdLoCO7uB"
   },
   "source": [
    "# Import Pre-trained RecoBERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model import BERT as pre_trained\n",
    "\n",
    "# Hyperparameters for pre-trained RecoBERT\n",
    "maxlen = 100 # maximum of length\n",
    "n_layers = 1 # number of Encoder of Encoder Layer\n",
    "n_heads = 4 # number of heads in Multi-Head Attention\n",
    "emb_dim = 128 # Embedding Size\n",
    "d_ff = 128 * 4  # 4*d_model, FeedForward dimension\n",
    "d_k = d_v = 64  # dimension of K(=Q), V\n",
    "n_segments = 2 # number of segments \n",
    "\n",
    "pre_trained_model = pre_trained(vocab_size, maxlen, emb_dim, n_segments, d_ff, n_layers, d_k, d_v, n_heads)\n",
    "pre_trained_model.load_state_dict(torch.load(\"recmodel.bin\", map_location=torch.device('cpu')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BERT(\n",
       "  (embedding): Embedding(\n",
       "    (tok_embed): Embedding(103866, 128)\n",
       "    (pos_embed): Embedding(100, 128)\n",
       "    (seg_embed): Embedding(2, 128)\n",
       "    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (layers): ModuleList(\n",
       "    (0): EncoderLayer(\n",
       "      (enc_self_attn): MultiHeadAttention(\n",
       "        (W_Q): Linear(in_features=128, out_features=256, bias=True)\n",
       "        (W_K): Linear(in_features=128, out_features=256, bias=True)\n",
       "        (W_V): Linear(in_features=128, out_features=256, bias=True)\n",
       "      )\n",
       "      (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "      (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (activ1): Tanh()\n",
       "  (linear): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  (classifier): Linear(in_features=128, out_features=2, bias=True)\n",
       "  (decoder): Linear(in_features=128, out_features=103866, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(pre_trained_model.classifier.in_features)\n",
    "print(pre_trained_model.classifier.out_features)\n",
    "\n",
    "in_features = pre_trained_model.classifier.in_features\n",
    "\n",
    "# Freeze pre-trained model parameters\n",
    "for param in pre_trained_model.parameters():\n",
    "     param.requires_grad = False\n",
    "        \n",
    "\n",
    "pre_trained_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wsm8bkRZQTw9"
   },
   "source": [
    "# Convert Integer Sequences to Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QR-lXwmzQPd6"
   },
   "outputs": [],
   "source": [
    "# Create tensors for training set\n",
    "train_seq = torch.tensor(tr_seq)\n",
    "train_mask = torch.tensor(tr_segment)\n",
    "train_y = torch.tensor(tr_labels)\n",
    "train_tok_pos = torch.tensor(tr_tok)\n",
    "\n",
    "\n",
    "# Create tensors for validation set\n",
    "val_seq = torch.tensor(v_seq)\n",
    "val_mask = torch.tensor(v_segment)\n",
    "val_y = torch.tensor(v_labels)\n",
    "val_tok_pos = torch.tensor(v_tok)\n",
    "\n",
    "# Create tensors for testing set\n",
    "test_seq = torch.tensor(te_seq)\n",
    "test_mask = torch.tensor(te_segment)\n",
    "test_y = torch.tensor(te_labels)\n",
    "test_tok_pos = torch.tensor(te_tok)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1638, 1638, 1638)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_seq), len(train_mask), len(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(351, 351, 351)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(v_seq), len(v_segment), len(v_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(351, 351, 351)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(te_seq), len(te_segment), len(te_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ov1cOBlcRLuk"
   },
   "source": [
    "# Create DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qUy9JKFYQYLp"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "#define a batch size\n",
    "batch_size = 10\n",
    "\n",
    "# wrap tensors\n",
    "train_data = TensorDataset(train_seq, train_mask, train_y, train_tok_pos)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "train_sampler = RandomSampler(train_data)\n",
    "\n",
    "# dataLoader for training set\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# wrap tensors\n",
    "val_data = TensorDataset(val_seq, val_mask, val_y, val_tok_pos)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "\n",
    "# dataLoader for validation set\n",
    "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)\n",
    "\n",
    "# wrap tensors\n",
    "test_data = TensorDataset(test_seq, test_mask, test_y, test_tok_pos)\n",
    "\n",
    "# sampler for sampling the data during testing\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "\n",
    "# dataLoader for testing set\n",
    "test_dataloader = DataLoader(test_data, sampler = test_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s7ahGBUWRi3X"
   },
   "source": [
    "# Define Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_to_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b3iEtGyYRd0A"
   },
   "outputs": [],
   "source": [
    "class BERT_Arch(nn.Module):\n",
    "\n",
    "    def __init__(self, pre_trained_model, cls_dim):\n",
    "      \n",
    "        super(BERT_Arch, self).__init__()\n",
    "        \n",
    "        pre_trained_model.classifier = nn.Linear(in_features, cls_dim)\n",
    "        self.bert = pre_trained_model\n",
    "        \n",
    "         \n",
    "\n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "        # relu activation function\n",
    "        self.relu =  nn.ReLU()\n",
    "\n",
    "        # MLP Linear layer 1\n",
    "        self.mlp_lin = nn.Linear(100,50)\n",
    "        \n",
    "        # MLP Linear classifier\n",
    "        self.mlp_lin2 = nn.Linear(50,gender_label_vocab)\n",
    "        \n",
    "        \n",
    "        # Transfer learning: Linear layer 1\n",
    "        self.mask_lin = nn.Linear(103866,512)\n",
    "        \n",
    "        # Transfer learning: Linear classifier \n",
    "        self.mask_lin2 = nn.Linear(512,gender_label_vocab)\n",
    "        \n",
    "    \n",
    "        #softmax activation function\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    #define the forward pass\n",
    "    def forward(self, sent_id, mask, masked_pos, device, n_heads, d_k, d_v, avg_tok=False, mlp=False):\n",
    "        \n",
    "        #pass the inputs to the model  \n",
    "        if mlp == False:\n",
    "            masked_out , cls_hs1, cls_hs2 = self.bert(sent_id, mask, masked_pos, device, n_heads, d_k, d_v)\n",
    "            \n",
    "            x = self.mask_lin(masked_out)\n",
    "            \n",
    "            x = self.relu(x) \n",
    "           \n",
    "            x = self.dropout(x)\n",
    "\n",
    "            # output layer\n",
    "            x = self.mask_lin2(x)\n",
    "           \n",
    "            # apply softmax activation\n",
    "            x = self.softmax(x)\n",
    "\n",
    "                \n",
    "        else:\n",
    "            sent_id = torch.tensor(sent_id, dtype=torch.float)\n",
    "            x = self.mlp_lin(sent_id)\n",
    "        \n",
    "            x = self.relu(x)\n",
    "\n",
    "            x = self.dropout(x)\n",
    "\n",
    "             # MLP linear classifier output\n",
    "            x = self.mlp_lin2(x)\n",
    "\n",
    "            # apply softmax activation\n",
    "            x = self.softmax(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j9CDpoMQR_rK"
   },
   "source": [
    "# Find Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "izY5xH5eR7Ur",
    "outputId": "4682d190-bf40-4824-89af-91983ae6b174"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "#compute the class weights\n",
    "#class_wts = compute_class_weight(class_weight='balanced', classes= np.unique(kandian_labels), y= kandian_labels)\n",
    "class_wts = compute_class_weight(class_weight='balanced', classes= np.unique(gender_target), y= gender_target)\n",
    "\n",
    "print(class_wts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r1WvfY2vSGKi"
   },
   "outputs": [],
   "source": [
    "# convert class weights to tensor\n",
    "weights= torch.tensor(class_wts,dtype=torch.float)\n",
    "weights = weights.to(device)\n",
    "\n",
    "# Define loss function\n",
    "cross_entropy  = nn.NLLLoss(weight=weights) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "My4CA0qaShLq"
   },
   "source": [
    "# Fine-Tune RecoBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rskLk8R_SahS"
   },
   "outputs": [],
   "source": [
    "# function to train the model\n",
    "def train(model, mlp, avg_tok):\n",
    "  \n",
    "  model.train()\n",
    "\n",
    "  total_loss, total_accuracy = 0, 0\n",
    "  \n",
    "  # empty list to save model predictions\n",
    "  total_preds=[]\n",
    "  \n",
    "  # iterate over batches\n",
    "  for step,batch in enumerate(train_dataloader):\n",
    "    \n",
    "    # push the batch to gpu\n",
    "    batch = [r.to(device) for r in batch]\n",
    " \n",
    "    sent_id, mask, labels, tok_pos = batch\n",
    "\n",
    "    # clear previously calculated gradients \n",
    "    model.zero_grad()        \n",
    "\n",
    "    # get model predictions for the current batch\n",
    "    preds = model(sent_id, mask, tok_pos , device, n_heads, \n",
    "                  d_k, d_v, avg_tok=avg_tok, mlp=mlp)\n",
    "    \n",
    "\n",
    "    # compute the loss between actual and predicted values\n",
    "    if mlp == False:\n",
    "        preds = torch.mean(preds, dim=1)\n",
    "    \n",
    "    \n",
    "    loss = cross_entropy(preds, labels)\n",
    "\n",
    "    # add on to the total loss\n",
    "    total_loss = total_loss + loss.item()\n",
    "\n",
    "    # backward pass to calculate the gradients\n",
    "    loss.backward()\n",
    "\n",
    "    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    # model predictions are stored on GPU. So, push it to CPU\n",
    "    preds=preds.detach().cpu().numpy()\n",
    "\n",
    "    # append the model predictions\n",
    "    total_preds.append(preds)\n",
    "\n",
    "  # compute the training loss of the epoch\n",
    "  avg_loss = total_loss / len(train_dataloader)\n",
    "  \n",
    "  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
    "  # reshape the predictions in form of (number of samples, no. of classes)\n",
    "  total_preds  = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "  #returns the loss, predictions, model\n",
    "  return avg_loss, total_preds, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yGXovFDlSxB5"
   },
   "outputs": [],
   "source": [
    "# function for evaluating the model\n",
    "def evaluate(model, mlp, avg_tok):\n",
    "  \n",
    "  # deactivate dropout layers\n",
    "  model.eval()\n",
    "\n",
    "  total_loss, total_accuracy = 0, 0\n",
    "  \n",
    "  # empty list to save the model predictions\n",
    "  total_preds = []\n",
    "\n",
    "  # iterate over batches\n",
    "  for step,batch in enumerate(val_dataloader):\n",
    "\n",
    "    # push the batch to gpu\n",
    "    batch = [t.to(device) for t in batch]\n",
    "\n",
    "    sent_id, mask, labels, tok_pos = batch\n",
    "\n",
    "    # deactivate autograd\n",
    "    with torch.no_grad():\n",
    "      \n",
    "      # model predictions\n",
    "      preds = model(sent_id, mask, tok_pos , device, n_heads, \n",
    "                    d_k, d_v, avg_tok=avg_tok, mlp=mlp)\n",
    "    \n",
    "      \n",
    "      \n",
    "      if mlp == False: \n",
    "          preds = torch.mean(preds, dim=1)\n",
    "        \n",
    "        \n",
    "      # compute the validation loss between actual and predicted values\n",
    "      loss = cross_entropy(preds,labels)\n",
    "\n",
    "      total_loss = total_loss + loss.item()\n",
    "\n",
    "      preds = preds.detach().cpu().numpy()\n",
    "\n",
    "      total_preds.append(preds)\n",
    "\n",
    "  # compute the validation loss of the epoch\n",
    "  avg_loss = total_loss / len(val_dataloader) \n",
    "\n",
    "  # reshape the predictions in form of (number of samples, no. of classes)\n",
    "  total_preds  = np.concatenate(total_preds, axis=0)\n",
    "    \n",
    "\n",
    "  return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9KZEgxRRTLXG"
   },
   "source": [
    "# Start Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def start(model, mlp, epochs):\n",
    "# set initial loss to infinite\n",
    "    best_valid_loss = float('inf')\n",
    "\n",
    "    # empty lists to store training and validation loss of each epoch\n",
    "    train_losses=[]\n",
    "    valid_losses=[]\n",
    "\n",
    "    #for each epoch\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        if epoch % 20== 0:\n",
    "            print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
    "\n",
    "        #train model\n",
    "        train_loss, _, model = train(model, mlp, avg_tok=False )\n",
    "\n",
    "        #evaluate model\n",
    "        valid_loss, _ = evaluate(model, mlp, avg_tok=False)\n",
    "\n",
    "        #save the best model\n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            torch.save(model.state_dict(), 'fine_tuned_weights.pt')\n",
    "\n",
    "        # append training and validation loss\n",
    "        train_losses.append(train_loss)\n",
    "        valid_losses.append(valid_loss)\n",
    "\n",
    "         # Print losses every 20 epochs\n",
    "        if epoch % 20== 0:\n",
    "            print(f'\\nTraining Loss: {train_loss:.3f}')\n",
    "            print(f'Validation Loss: {valid_loss:.3f}')\n",
    "\n",
    "        \n",
    "        \n",
    "    return train_losses, valid_losses, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions for test data\n",
    "def get_accuracy(model, mlp):\n",
    "    test_preds = []\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for step,batch in enumerate(test_dataloader):\n",
    "\n",
    "            # push the batch to gpu\n",
    "            batch = [t.to(device) for t in batch]\n",
    "\n",
    "            sent_id, mask, labels, tok_pos  = batch   \n",
    "            \n",
    "            \n",
    "            preds = model(sent_id, mask, tok_pos , device, n_heads, d_k, d_v, avg_tok=False, mlp=mlp)\n",
    "        \n",
    "            if mlp == False:\n",
    "                preds = torch.mean(preds, dim=1)\n",
    "            preds = preds.detach().cpu().numpy()\n",
    "            test_preds.append(preds)\n",
    "\n",
    "    test_preds_concat =np.concatenate( test_preds, axis=0 )\n",
    " \n",
    "    preds = np.argmax(test_preds_concat, axis = 1)\n",
    "  \n",
    "    print(\"predicted Gender:\\n\",preds)\n",
    "    print(\"True Gender:\\n\",test_y)\n",
    "    print(\"Accuracy score: \",int(accuracy_score(test_y,preds)*100 ),\"%\")\n",
    "    \n",
    "    print(classification_report(test_y, preds))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free up memory for training\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gender Classification: Training and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model A: MLP \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mistgpu/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_720/320170383.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sent_id = torch.tensor(sent_id, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 / 300\n",
      "\n",
      "Training Loss: 868.340\n",
      "Validation Loss: 215.453\n",
      "\n",
      " Epoch 21 / 300\n",
      "\n",
      "Training Loss: 0.673\n",
      "Validation Loss: 1.098\n",
      "\n",
      " Epoch 41 / 300\n",
      "\n",
      "Training Loss: 0.674\n",
      "Validation Loss: 1.100\n",
      "\n",
      " Epoch 61 / 300\n",
      "\n",
      "Training Loss: 0.675\n",
      "Validation Loss: 1.100\n",
      "\n",
      " Epoch 81 / 300\n",
      "\n",
      "Training Loss: 0.672\n",
      "Validation Loss: 1.104\n",
      "\n",
      " Epoch 101 / 300\n",
      "\n",
      "Training Loss: 0.672\n",
      "Validation Loss: 1.106\n",
      "\n",
      " Epoch 121 / 300\n",
      "\n",
      "Training Loss: 0.673\n",
      "Validation Loss: 1.119\n",
      "\n",
      " Epoch 141 / 300\n",
      "\n",
      "Training Loss: 0.672\n",
      "Validation Loss: 1.122\n",
      "\n",
      " Epoch 161 / 300\n",
      "\n",
      "Training Loss: 0.671\n",
      "Validation Loss: 1.124\n",
      "\n",
      " Epoch 181 / 300\n",
      "\n",
      "Training Loss: 0.673\n",
      "Validation Loss: 1.125\n",
      "\n",
      " Epoch 201 / 300\n",
      "\n",
      "Training Loss: 0.672\n",
      "Validation Loss: 1.126\n",
      "\n",
      " Epoch 221 / 300\n",
      "\n",
      "Training Loss: 0.672\n",
      "Validation Loss: 1.127\n",
      "\n",
      " Epoch 241 / 300\n",
      "\n",
      "Training Loss: 0.673\n",
      "Validation Loss: 1.127\n",
      "\n",
      " Epoch 261 / 300\n",
      "\n",
      "Training Loss: 0.673\n",
      "Validation Loss: 1.128\n",
      "\n",
      " Epoch 281 / 300\n",
      "\n",
      "Training Loss: 0.674\n",
      "Validation Loss: 1.128\n",
      "predicted Ages:\n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1]\n",
      "True Ages:\n",
      " tensor([1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
      "        0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
      "        1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
      "        0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0,\n",
      "        1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0,\n",
      "        1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
      "        1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n",
      "        1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1,\n",
      "        1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
      "        1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1,\n",
      "        1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1,\n",
      "        1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
      "        0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n",
      "        1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1,\n",
      "        1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0])\n",
      "Accuracy score:  51 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.03      0.07       172\n",
      "           1       0.51      0.98      0.68       179\n",
      "\n",
      "    accuracy                           0.52       351\n",
      "   macro avg       0.59      0.51      0.37       351\n",
      "weighted avg       0.59      0.52      0.38       351\n",
      "\n",
      "elapsed time: 120.75007390975952\n",
      "-------------------------------------------\n",
      "Training model B: Freeze + Fine-tune \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mistgpu/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 / 300\n",
      "\n",
      "Training Loss: 88.519\n",
      "Validation Loss: 25.873\n",
      "\n",
      " Epoch 21 / 300\n",
      "\n",
      "Training Loss: 21.841\n",
      "Validation Loss: 19.386\n",
      "\n",
      " Epoch 41 / 300\n",
      "\n",
      "Training Loss: 24.217\n",
      "Validation Loss: 19.870\n",
      "\n",
      " Epoch 61 / 300\n",
      "\n",
      "Training Loss: 25.428\n",
      "Validation Loss: 21.938\n",
      "\n",
      " Epoch 81 / 300\n",
      "\n",
      "Training Loss: 24.793\n",
      "Validation Loss: 19.791\n",
      "\n",
      " Epoch 101 / 300\n",
      "\n",
      "Training Loss: 26.196\n",
      "Validation Loss: 23.001\n",
      "\n",
      " Epoch 121 / 300\n",
      "\n",
      "Training Loss: 25.642\n",
      "Validation Loss: 20.971\n",
      "\n",
      " Epoch 141 / 300\n",
      "\n",
      "Training Loss: 25.052\n",
      "Validation Loss: 20.849\n",
      "\n",
      " Epoch 161 / 300\n",
      "\n",
      "Training Loss: 24.998\n",
      "Validation Loss: 21.283\n",
      "\n",
      " Epoch 181 / 300\n",
      "\n",
      "Training Loss: 24.253\n",
      "Validation Loss: 21.848\n",
      "\n",
      " Epoch 201 / 300\n",
      "\n",
      "Training Loss: 24.923\n",
      "Validation Loss: 21.510\n",
      "\n",
      " Epoch 221 / 300\n",
      "\n",
      "Training Loss: 25.699\n",
      "Validation Loss: 22.236\n",
      "\n",
      " Epoch 241 / 300\n",
      "\n",
      "Training Loss: 25.695\n",
      "Validation Loss: 21.760\n",
      "\n",
      " Epoch 261 / 300\n",
      "\n",
      "Training Loss: 27.315\n",
      "Validation Loss: 20.356\n",
      "\n",
      " Epoch 281 / 300\n",
      "\n",
      "Training Loss: 25.553\n",
      "Validation Loss: 22.455\n",
      "predicted Ages:\n",
      " [1 0 1 0 1 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 1 1 0 0 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 0 0 1 1 1 0 0 0 1 0 1 0 0 0 0 0\n",
      " 0 1 0 1 0 0 0 0 0 1 1 0 0 1 0 1 1 0 0 0 1 1 1 1 0 1 0 1 1 1 0 1 1 0 1 0 0\n",
      " 1 1 0 1 1 1 0 1 1 1 1 0 1 0 0 0 1 0 0 0 1 1 0 1 1 0 1 0 1 1 0 0 0 0 1 0 1\n",
      " 0 1 0 1 1 0 1 1 0 1 0 0 1 0 0 1 1 0 0 1 1 0 0 1 1 1 0 0 0 1 1 0 1 0 1 1 0\n",
      " 1 0 0 1 1 1 0 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 1 0 1 1 1 1 0 1 0 0 0 1 0 0 0\n",
      " 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 1 1 0 0 1 1 0 1 0 1 0\n",
      " 0 0 1 1 1 0 1 1 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 1 0 0 1 1 1 0 1 0 1 0 1 0\n",
      " 1 0 0 0 1 1 0 0 1 0 1 1 1 0 0 1 1 0 1 0 0 0 0 1 1 0 1 1 0 1 0 0 0 0 0 0 1\n",
      " 0 1 0 1 1 0 0 0 0 0 1 1 1 1 0 0 0 1]\n",
      "True Ages:\n",
      " tensor([1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
      "        0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
      "        1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
      "        0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0,\n",
      "        1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0,\n",
      "        1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
      "        1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n",
      "        1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1,\n",
      "        1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
      "        1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1,\n",
      "        1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1,\n",
      "        1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
      "        0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n",
      "        1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1,\n",
      "        1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0])\n",
      "Accuracy score:  54 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.62      0.58       172\n",
      "           1       0.57      0.48      0.52       179\n",
      "\n",
      "    accuracy                           0.55       351\n",
      "   macro avg       0.55      0.55      0.55       351\n",
      "weighted avg       0.55      0.55      0.55       351\n",
      "\n",
      "elapsed time: 593.2105603218079\n",
      "-------------------------------------------\n",
      "Training model C: Fine-tune all \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mistgpu/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 / 300\n",
      "\n",
      "Training Loss: 39.147\n",
      "Validation Loss: 2.943\n",
      "\n",
      " Epoch 21 / 300\n",
      "\n",
      "Training Loss: 0.745\n",
      "Validation Loss: 0.693\n",
      "\n",
      " Epoch 41 / 300\n",
      "\n",
      "Training Loss: 0.730\n",
      "Validation Loss: 0.693\n",
      "\n",
      " Epoch 61 / 300\n",
      "\n",
      "Training Loss: 0.733\n",
      "Validation Loss: 0.693\n",
      "\n",
      " Epoch 81 / 300\n",
      "\n",
      "Training Loss: 0.722\n",
      "Validation Loss: 0.693\n",
      "\n",
      " Epoch 101 / 300\n",
      "\n",
      "Training Loss: 0.718\n",
      "Validation Loss: 0.693\n",
      "\n",
      " Epoch 121 / 300\n",
      "\n",
      "Training Loss: 0.717\n",
      "Validation Loss: 0.693\n",
      "\n",
      " Epoch 141 / 300\n",
      "\n",
      "Training Loss: 0.716\n",
      "Validation Loss: 0.693\n",
      "\n",
      " Epoch 161 / 300\n",
      "\n",
      "Training Loss: 0.716\n",
      "Validation Loss: 0.693\n",
      "\n",
      " Epoch 181 / 300\n",
      "\n",
      "Training Loss: 0.712\n",
      "Validation Loss: 0.693\n",
      "\n",
      " Epoch 201 / 300\n",
      "\n",
      "Training Loss: 0.711\n",
      "Validation Loss: 0.693\n",
      "\n",
      " Epoch 221 / 300\n",
      "\n",
      "Training Loss: 0.713\n",
      "Validation Loss: 0.693\n",
      "\n",
      " Epoch 241 / 300\n",
      "\n",
      "Training Loss: 0.708\n",
      "Validation Loss: 0.693\n",
      "\n",
      " Epoch 261 / 300\n",
      "\n",
      "Training Loss: 0.712\n",
      "Validation Loss: 0.693\n",
      "\n",
      " Epoch 281 / 300\n",
      "\n",
      "Training Loss: 0.708\n",
      "Validation Loss: 0.693\n",
      "predicted Ages:\n",
      " [1 1 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 0 1 1 1 0 1 1 0 1 1 1 1 0 1 0 1 1 1\n",
      " 1 1 0 1 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 1 0 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1\n",
      " 0 0 0 0 0 1 1 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 0 1 1 0 0 1 0 1 1 0 1 1 1\n",
      " 1 0 1 0 1 0 0 1 1 1 0 0 1 1 0 0 0 1 1 0 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 0 1 0 1 0 0 0 1 1 1 0 0 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 0 1 0 0 0 0 1 0 1 0\n",
      " 0 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 0 1 0 0 0 1\n",
      " 0 0 1 1 1 1 0 1 1 0 1 0 1 0 0 0 1 1 0 1 0 0 1 1 1 1 0 1 1 0 1 1 0 1 0 1 1\n",
      " 0 1 1 1 0 0 0 1 0 1 1 0 1 0 0 0 1 1 0 1 1 0 0 1 1 1 1 1 1 1 0 0 1 0 1 0 0\n",
      " 1 1 1 1 1 1 1 0 0 1 0 0 1 0 0 0 0 1 1 0 1 0 1 0 0 1 0 1 1 0 1 1 0 1 1 1 1\n",
      " 0 0 0 1 1 1 1 1 1 0 1 0 1 0 0 0 1 0]\n",
      "True Ages:\n",
      " tensor([1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
      "        0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
      "        1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
      "        0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0,\n",
      "        1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0,\n",
      "        1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
      "        1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n",
      "        1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1,\n",
      "        1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
      "        1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1,\n",
      "        1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1,\n",
      "        1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
      "        0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n",
      "        1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1,\n",
      "        1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0])\n",
      "Accuracy score:  49 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.40      0.44       172\n",
      "           1       0.51      0.59      0.55       179\n",
      "\n",
      "    accuracy                           0.50       351\n",
      "   macro avg       0.50      0.50      0.49       351\n",
      "weighted avg       0.50      0.50      0.49       351\n",
      "\n",
      "elapsed time: 853.9372844696045\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# optimizer from hugging face transformers\n",
    "import time\n",
    "from transformers import AdamW\n",
    "\n",
    "# number of training epochs\n",
    "epochs = 300\n",
    "\n",
    "########################### Model A ############################\n",
    "print(\"Training model A: MLP \")\n",
    "start_time = time.time()\n",
    "modelA = BERT_Arch(pre_trained_model,300) # Initialize the fine-tuning model\n",
    "modelA = modelA.to(device)\n",
    "# define the optimizer\n",
    "optimizer = AdamW(modelA.parameters(), lr = 1e-3)\n",
    "train_losses, valid_losses, modelA = start(modelA, True, epochs)# True here means we want to turn off \n",
    "                                                        # transfer learning, and use the simple MLP model\n",
    "elapsed_time = (time.time() - start_time)\n",
    "get_accuracy(modelA, True)\n",
    "print(\"elapsed time:\" ,elapsed_time)\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "########################### Model B ############################\n",
    "print(\"Training model B: Freeze + Fine-tune \")\n",
    "start_time = time.time()\n",
    "# pass the pre-trained RecoBERT to our define architecture\n",
    "modelB = BERT_Arch(pre_trained_model,300)\n",
    "modelB = modelB.to(device)\n",
    "# define the optimizer\n",
    "optimizer = AdamW(modelB.parameters(), lr = 1e-3)\n",
    "train_losses2, valid_losses2, modelB = start(modelB,False, epochs) \n",
    "elapsed_time = (time.time() - start_time)\n",
    "get_accuracy(modelB, False)\n",
    "print(\"elapsed time:\" ,elapsed_time)\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "\n",
    "############################# Model C ############################\n",
    "print(\"Training model C: Fine-tune all \")\n",
    "#epochs = 10\n",
    "start_time = time.time()\n",
    "# Unfreeze pre-trained weights\n",
    "for param in pre_trained_model.parameters():\n",
    "     param.requires_grad = True\n",
    "modelC = BERT_Arch(pre_trained_model,300)\n",
    "modelC = modelC.to(device)\n",
    "# define the optimizer\n",
    "optimizer = AdamW(modelC.parameters(), lr = 1e-3)\n",
    "train_losses3, valid_losses3, modelC = start(modelC,False, epochs)\n",
    "elapsed_time = (time.time() - start_time)\n",
    "get_accuracy(modelC, False)\n",
    "print(\"elapsed time:\" ,elapsed_time)\n",
    "print(\"-------------------------------------------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_plot = range(1, epochs+1)\n",
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(10, 7))\n",
    "axes.plot(epochs_plot, valid_losses, 'g', label='MLP')\n",
    "axes.plot(epochs_plot, valid_losses2, 'b', label='Freeze + Fine-tune ')\n",
    "axes.plot(epochs_plot, valid_losses3, 'm', label='Fine-tune all')\n",
    "axes.set(ylabel='Loss')\n",
    "axes.set(xlabel='Epochs')\n",
    "axes.legend(loc='upper right')\n",
    "axes.set_title('Fine-Tuning Validation Loss')\n",
    "plt.axis([1, 300, 0, 2])\n",
    "plt.savefig('Gendernewloss1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOt9x7x5Cm/ENCEI4+c+LvL",
   "include_colab_link": true,
   "name": "Fine-Tuning BERT for Spam Classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0e580433bec2453da54c0ce9ee027401": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_73fc7587f1bb49df8a0fc87ecfac7f3c",
       "IPY_MODEL_4da1c15300b2468ab1a7e2df800ed39b"
      ],
      "layout": "IPY_MODEL_bdfd7634b8bf42aa8794ada8d9e47173"
     }
    },
    "3bb6b624b4ce4be788c38cb8d1936177": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "47862cd626cf46619a5cc505fde02276": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "49dd79a9a65044ba8345deb250ce4b24": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "4d56a47453914de3be15d7a515e5b210": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "4da1c15300b2468ab1a7e2df800ed39b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_88214abee8b9462f86369072d858ae9f",
      "placeholder": "​",
      "style": "IPY_MODEL_ed9f97f9d12a49aa939b7595ad3cb27c",
      "value": " 440M/440M [00:11&lt;00:00, 37.5MB/s]"
     }
    },
    "58cd585c531444a5b8613c2d85bab022": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "59bae99ad63d4a3a8b8d622d95f7ad07": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_47862cd626cf46619a5cc505fde02276",
      "max": 433,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_49dd79a9a65044ba8345deb250ce4b24",
      "value": 433
     }
    },
    "645d520e8a1c4f1fa202c6c68c5ce6af": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "6831c2b733d74b31a41cb6eb971a25d7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "689e66a8dff249449b5f0f5bbfffa037": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6d2355752eb74f348596a380d2347b73",
      "placeholder": "​",
      "style": "IPY_MODEL_cb5f7a2a5bcb47649703cc633f2fb685",
      "value": " 433/433 [00:00&lt;00:00, 1.98kB/s]"
     }
    },
    "6d2355752eb74f348596a380d2347b73": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "73fc7587f1bb49df8a0fc87ecfac7f3c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3bb6b624b4ce4be788c38cb8d1936177",
      "max": 440473133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_645d520e8a1c4f1fa202c6c68c5ce6af",
      "value": 440473133
     }
    },
    "88214abee8b9462f86369072d858ae9f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8cf06dad410440f78c50e3527e858905": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6831c2b733d74b31a41cb6eb971a25d7",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4d56a47453914de3be15d7a515e5b210",
      "value": 231508
     }
    },
    "94264f36ceb64d3881fed952bf579072": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "983fea7c2dc74dfaba7aa60147af85d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_59bae99ad63d4a3a8b8d622d95f7ad07",
       "IPY_MODEL_689e66a8dff249449b5f0f5bbfffa037"
      ],
      "layout": "IPY_MODEL_ccf5f7e5cc10493ca9c44b14fdec31dc"
     }
    },
    "b4bef5a685954e238b52c43eefe4c9e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8cf06dad410440f78c50e3527e858905",
       "IPY_MODEL_edf0e4c1ae214a66abb717b20e3bffad"
      ],
      "layout": "IPY_MODEL_94264f36ceb64d3881fed952bf579072"
     }
    },
    "b6423c858927455e8cbc5a953273466a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bdfd7634b8bf42aa8794ada8d9e47173": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cb5f7a2a5bcb47649703cc633f2fb685": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ccf5f7e5cc10493ca9c44b14fdec31dc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ed9f97f9d12a49aa939b7595ad3cb27c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "edf0e4c1ae214a66abb717b20e3bffad": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b6423c858927455e8cbc5a953273466a",
      "placeholder": "​",
      "style": "IPY_MODEL_58cd585c531444a5b8613c2d85bab022",
      "value": " 232k/232k [00:39&lt;00:00, 5.82kB/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
